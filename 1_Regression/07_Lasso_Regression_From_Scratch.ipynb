{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Lasso Regression From Scratch\n",
                "\n",
                "Lasso (Least Absolute Shrinkage and Selection Operator) adds an **L1 penalty** to the cost function. Unlike Ridge, Lasso can shrink coefficients exactly to zero, performing automated **feature selection**.\n",
                "\n",
                "## Key Concepts:\n",
                "- **L1 Regularization**: Penalty of $\\alpha \\sum |w_j|$\n",
                "- **Coordinate Descent**: Standard iterative algorithm for Lasso\n",
                "- **Soft Thresholding**: The operator used to update weights\n",
                "- **Sparsity**: Produces sparse models (many zero weights)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "from sklearn.datasets import make_regression\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from sklearn.linear_model import Lasso as SklearnLasso"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Mathematical Foundation\n",
                "\n",
                "### Cost Function\n",
                "$$J(w, b) = \\frac{1}{2n} \\sum_{i=1}^n (y_i - (X_i w + b))^2 + \\alpha \\sum_{j=1}^m |w_j|$$\n",
                "\n",
                "### Coordinate Descent Update\n",
                "For each feature $j$:\n",
                "1. Calculate the partial fit without feature $j$: $\\rho_j = \\sum_{i=1}^n x_{ij} (y_i - (\\sum_{k \\neq j} x_{ik} w_k + b))$\n",
                "2. Normalize the feature: $z_j = \\sum_{i=1}^n x_{ij}^2$\n",
                "3. Apply **Soft Thresholding**:\n",
                "   $$w_j = S(\\rho_j, \\alpha \\cdot n) / z_j$$\n",
                "   Where $S(z, \\gamma) = \\text{sign}(z) \\max(|z| - \\gamma, 0)$"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class LassoRegression:\n",
                "    def __init__(self, alpha=1.0, max_iter=1000, tol=1e-4):\n",
                "        self.alpha = alpha\n",
                "        self.max_iter = max_iter\n",
                "        self.tol = tol\n",
                "        self.w = None\n",
                "        self.b = 0\n",
                "\n",
                "    def _soft_threshold(self, rho, lam):\n",
                "        if rho < -lam:\n",
                "            return rho + lam\n",
                "        elif rho > lam:\n",
                "            return rho - lam\n",
                "        else:\n",
                "            return 0\n",
                "\n",
                "    def fit(self, X, y):\n",
                "        n_samples, n_features = X.shape\n",
                "        self.w = np.zeros(n_features)\n",
                "        self.b = np.mean(y)\n",
                "        \n",
                "        for _ in range(self.max_iter):\n",
                "            w_old = self.w.copy()\n",
                "            \n",
                "            for j in range(n_features):\n",
                "                # Calculate rho_j: sum(x_ij * (y_i - y_pred_without_j))\n",
                "                y_pred = X @ self.w + self.b\n",
                "                rho = np.dot(X[:, j], y - y_pred + self.w[j] * X[:, j])\n",
                "                \n",
                "                # Update weight using soft thresholding\n",
                "                # Note: alpha is scaled by n_samples in many implementations\n",
                "                self.w[j] = self._soft_threshold(rho, self.alpha * n_samples) / np.sum(X[:, j]**2)\n",
                "            \n",
                "            # Update bias\n",
                "            self.b = np.mean(y - X @ self.w)\n",
                "            \n",
                "            # Convergence check\n",
                "            if np.linalg.norm(self.w - w_old) < self.tol:\n",
                "                break\n",
                "                \n",
                "        return self\n",
                "\n",
                "    def predict(self, X):\n",
                "        return X @ self.w + self.b\n",
                "\n",
                "    def score(self, X, y):\n",
                "        y_pred = self.predict(X)\n",
                "        return 1 - np.sum((y - y_pred)**2) / np.sum((y - np.mean(y))**2)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Comparison with Sklearn\n",
                "\n",
                "We use feature scaling as Lasso is sensitive to feature magnitude."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "X, y = make_regression(n_samples=100, n_features=10, n_informative=3, noise=10, random_state=42)\n",
                "scaler = StandardScaler()\n",
                "X = scaler.fit_transform(X)\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                "\n",
                "alpha = 1.0\n",
                "\n",
                "lasso = LassoRegression(alpha=alpha)\n",
                "lasso.fit(X_train, y_train)\n",
                "\n",
                "sk_lasso = SklearnLasso(alpha=alpha)\n",
                "sk_lasso.fit(X_train, y_train)\n",
                "\n",
                "print(f\"Our Lasso R2: {lasso.score(X_test, y_test):.4f}\")\n",
                "print(f\"Sklearn Lasso R2: {sk_lasso.score(X_test, y_test):.4f}\")\n",
                "\n",
                "print(\"\\nCoefficients Comparison (first 5):\")\n",
                "print(f\"Our: {lasso.w[:5]}\")\n",
                "print(f\"SK:  {sk_lasso.coef_[:5]}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Visualizing Feature Selection\n",
                "\n",
                "Watch how coefficients go to zero as alpha increases."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "alphas = [1e-3, 0.1, 1, 10, 100]\n",
                "coeff_matrix = []\n",
                "\n",
                "for a in alphas:\n",
                "    l = LassoRegression(alpha=a)\n",
                "    l.fit(X_train, y_train)\n",
                "    coeff_matrix.append(l.w)\n",
                "\n",
                "plt.figure(figsize=(10, 6))\n",
                "plt.plot(alphas, coeff_matrix)\n",
                "plt.xscale('log')\n",
                "plt.xlabel('Alpha')\n",
                "plt.ylabel('Coefficients Value')\n",
                "plt.title('Lasso Paths - Feature Selection')\n",
                "plt.grid(True)\n",
                "plt.show()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}