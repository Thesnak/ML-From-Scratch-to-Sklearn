{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# AdaBoost Classifier From Scratch\n",
                "\n",
                "AdaBoost (Adaptive Boosting) is an ensemble method that combines multiple \"weak learners\" (usually Decision Stumps) into one strong learner by focusing on previously misclassified samples.\n",
                "\n",
                "## Key Concepts:\n",
                "- **Weak Learner**: A model that performs slightly better than random guessing\n",
                "- **Decision Stump**: A Decision Tree with only one split (depth=1)\n",
                "- **Sample Weights**: Misclassified samples get higher weights in the next round\n",
                "- **Alpha (Learner Weight)**: How much we trust each weak learner"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "from sklearn.datasets import make_moons\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.ensemble import AdaBoostClassifier as SklearnAda"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Decision Stump Implementation\n",
                "\n",
                "A decision stump is a single-split tree. To train it with weights, we search for the split that minimizes the **weighted error**."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class DecisionStump:\n",
                "    def __init__(self):\n",
                "        self.feature_idx = None\n",
                "        self.threshold = None\n",
                "        self.polarity = 1 # Direction of < threshold\n",
                "        self.alpha = None\n",
                "\n",
                "    def predict(self, X):\n",
                "        n_samples = X.shape[0]\n",
                "        X_column = X[:, self.feature_idx]\n",
                "        predictions = np.ones(n_samples)\n",
                "        if self.polarity == 1:\n",
                "            predictions[X_column < self.threshold] = -1\n",
                "        else:\n",
                "            predictions[X_column >= self.threshold] = -1\n",
                "        return predictions"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. AdaBoost Implementation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class AdaBoostClassifier:\n",
                "    def __init__(self, n_estimators=50):\n",
                "        self.n_estimators = n_estimators\n",
                "        self.stumps = []\n",
                "\n",
                "    def fit(self, X, y):\n",
                "        n_samples, n_features = X.shape\n",
                "        # Weights initialized to 1/N\n",
                "        w = np.full(n_samples, (1 / n_samples))\n",
                "        \n",
                "        self.stumps = []\n",
                "\n",
                "        for _ in range(self.n_estimators):\n",
                "            stump = DecisionStump()\n",
                "            min_error = float('inf')\n",
                "\n",
                "            # Find best split for weighted error\n",
                "            for f_idx in range(n_features):\n",
                "                X_column = X[:, f_idx]\n",
                "                thresholds = np.unique(X_column)\n",
                "                for threshold in thresholds:\n",
                "                    for polarity in [1, -1]:\n",
                "                        # Predict\n",
                "                        predictions = np.ones(n_samples)\n",
                "                        if polarity == 1:\n",
                "                            predictions[X_column < threshold] = -1\n",
                "                        else:\n",
                "                            predictions[X_column >= threshold] = -1\n",
                "\n",
                "                        # Weighted error calculation\n",
                "                        error = sum(w[y != predictions])\n",
                "                        \n",
                "                        if error < min_error:\n",
                "                            min_error = error\n",
                "                            stump.threshold = threshold\n",
                "                            stump.feature_idx = f_idx\n",
                "                            stump.polarity = polarity\n",
                "\n",
                "            # Calculate Alpha (Amount of Say)\n",
                "            # EPS to avoid division by zero\n",
                "            EPS = 1e-10\n",
                "            stump.alpha = 0.5 * np.log((1.0 - min_error + EPS) / (min_error + EPS))\n",
                "\n",
                "            # Update Weights\n",
                "            predictions = stump.predict(X)\n",
                "            w *= np.exp(-stump.alpha * y * predictions)\n",
                "            # Normalize\n",
                "            w /= np.sum(w)\n",
                "\n",
                "            self.stumps.append(stump)\n",
                "\n",
                "    def predict(self, X):\n",
                "        stump_preds = [stump.alpha * stump.predict(X) for stump in self.stumps]\n",
                "        y_pred = np.sum(stump_preds, axis=0)\n",
                "        return np.sign(y_pred)\n",
                "\n",
                "    def score(self, X, y):\n",
                "        return np.mean(self.predict(X) == y)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Testing on Moons Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "X, y = make_moons(n_samples=200, noise=0.1, random_state=42)\n",
                "# Change labels to {-1, 1} for AdaBoost\n",
                "y = np.where(y == 0, -1, 1)\n",
                "\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                "\n",
                "ada = AdaBoostClassifier(n_estimators=10)\n",
                "ada.fit(X_train, y_train)\n",
                "print(f\"Our AdaBoost Accuracy: {ada.score(X_test, y_test):.4f}\")\n",
                "\n",
                "sk_ada = SklearnAda(n_estimators=10, algorithm='SAMME')\n",
                "sk_ada.fit(X_train, y_train)\n",
                "print(f\"Sklearn AdaBoost Accuracy: {sk_ada.score(X_test, y_test):.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Visualizing Decision Boundaries"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "h = 0.02\n",
                "x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\n",
                "y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\n",
                "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
                "\n",
                "Z = ada.predict(np.c_[xx.ravel(), yy.ravel()])\n",
                "Z = Z.reshape(xx.shape)\n",
                "\n",
                "plt.contourf(xx, yy, Z, cmap=plt.cm.RdBu, alpha=0.8)\n",
                "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.RdBu, edgecolors='k')\n",
                "plt.title(\"AdaBoost Decision Boundary\")\n",
                "plt.show()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}